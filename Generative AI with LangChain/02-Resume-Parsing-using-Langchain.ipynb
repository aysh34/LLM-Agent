{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b681cd-0a1d-44f1-b2ca-231d98921fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in d:\\anaconda3\\lib\\site-packages (2.1.9)\n",
      "Requirement already satisfied: langchain-together in d:\\anaconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: pypdf in d:\\anaconda3\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: docx2txt in d:\\anaconda3\\lib\\site-packages (0.9)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.3.74)\n",
      "Requirement already satisfied: pydantic<3,>=2 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (2.10.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.32.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in d:\\anaconda3\\lib\\site-packages (from langchain-together) (3.11.10)\n",
      "Requirement already satisfied: langchain-openai<0.4,>=0.3 in d:\\anaconda3\\lib\\site-packages (from langchain-together) (0.3.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.18.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in d:\\anaconda3\\lib\\site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (1.100.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\anaconda3\\lib\\site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4,>=0.3->langchain-together) (2024.11.6)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai langchain-together pypdf docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4c826-33a1-4290-9490-85118ed09382",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa90cd6-a221-4b22-8144-fcf512fa7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70864b78-6162-48cb-b595-15f75fe1b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f7a5fc-db28-4df3-b523-d60848cfd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash',api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af40227f-0643-42c4-95ba-ae7c993532c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.invoke('Summarize the bias-variance tradeoff.').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc869738-b763-40c0-b404-8b137481fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert resume parser. Your task is to extract structured information from the resume text below.\n",
    "\n",
    "Return the output as a **single valid JSON object** with the exact following schema:\n",
    "\n",
    "{{\n",
    "  \"Name\": \"string\",\n",
    "  \"Email\": \"string\",\n",
    "  \"Phone\": \"string\",\n",
    "  \"LinkedIn\": \"string\",\n",
    "  \"Skills\": [\"string\"],\n",
    "  \"Education\": [\"string\"],\n",
    "  \"Experience\": [\"string\"],\n",
    "  \"Projects\": [\"string\"],\n",
    "  \"Certifications\": [\"string\"],\n",
    "  \"Languages\": [\"string\"]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- If a field cannot be found, set its value to \"No idea\".\n",
    "- Do not add explanations, notes, or extra text — output JSON only.\n",
    "- For lists (Skills, Education, Experience, Projects, Certifications, Languages), return an array of short strings.\n",
    "- Keep the JSON compact and properly formatted.\n",
    "\n",
    "Resume text:\n",
    "{text}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c58279-4f75-4e77-a993-973ac1e21942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate(\n",
    "#     template=PROMPT_TEMPLATE,\n",
    "#     input_variables=[\"text\"])\n",
    "# formatted_prompt = prompt.format(text=\"Jane Doe, ML Engineer skilled in TensorFlow, PyTorch...\")\n",
    "\n",
    "\n",
    "# Instantiation using from_template (recommended, automatically detect variables)\n",
    "# build prompt\n",
    "prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc569f44-dcfa-4118-8338-528a56f82ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_prompt = prompt.format(text=\"John Doe, Software Engineer with skills in Python, SQL...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d5d56c-d74c-484f-8e42-8c140aa6d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea52a79f-1e3e-486b-99df-e8753a642a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resume(file_path):\n",
    "    if file_path.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.lower().endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    elif file_path.lower().endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path)\n",
    "    else:\n",
    "        return None\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "49f1d3d3-37d2-4509-93ca-7ac05d93d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = load_resume(\"Ayesha_Saleem.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a9a3d0f-d193-482e-9b1f-75bda71fd15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-08-22T12:26:38+05:00', 'author': 'Ayesha Saleem', 'moddate': '2025-08-22T12:26:38+05:00', 'source': 'Ayesha_Saleem.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}, page_content='AYESHA SALEEM  \\n+92 318 6706803 | ayeshasaleem853@gmail.com | Portfolio | GitHub | Kaggle  | LinkedIn  \\nACHIEVEMENTS & COMPETITIONS \\n• @Kaggle Expert: Published datasets, notebooks, and competed in real-world ML challenges. \\n• @Harvard CS50x Puzzle Day Winner (2025): Solved all 9/9 puzzles; secured 1st place globally with \\nteam. \\n• @Meta Hacker Cup (2024) Qualifier: Competed in Meta’s global programming competition, showcasing \\nstrong algorithmic and problem-solving skills. \\n• @UC Berkeley CALICO Informatics Competition (2024): Participated to enhance data handling and \\ncomputational thinking. \\n• @LabLab.ai AI Hackathons: Participated in multiple international hackathons focused on generative \\nand applied AI. \\n• @LeetCode 230+ DSA Problems Solved: Practiced advanced algorithmic skills and competitive \\ncoding. \\n \\nTECHNICAL SKILLS \\n• Programming Languages: C++, Python  \\n• Data Science and Machine Learning: NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn, Plotly, \\nTensorFlow, PyTorch, Keras, OpenCV, Hugging face \\n• Frameworks: Streamlit, Gradio  \\n• Version Control: Git, Github  \\n• Developer Tools: VS Code, GoogleCollab, Anaconda, Jupyter Notebook  \\n• Design Tools: Canva \\n \\nEDUCATION  \\nEmerson University Multan                                                                                                Sep. 2023 – Present  \\nBachelor of Science in Computer Science                                                                      Multan, Punjab, Pakistan \\nCGPA: 3.86/4.0  \\nCoursework: Data Structures and Algorithms, Artificial Intelligence, Programming Fundamentals, OOP \\n  \\nEXPERIENCE  \\nC++ Programming Intern                                                                                                 May 2024 – June 2024   \\nCodeAlpha                                                                                                                                                 Remote              \\n• Developed hands-on projects using C++ programming language.  \\n• Gained experience in Object-Oriented Programming (OOP) and Data Structures. \\nContributed to real-world applications by writing clean and efficient code.  \\nKaggle Professional                                                                                                            Sep. 2024 – Present  \\nData Science Community Expert                                                                                                                Global               \\n• Published datasets and notebooks, contributing to the Kaggle community.  \\n• Created and shared data analysis notebooks showcasing Exploratory Data Analysis (EDA) and \\nMachine Learning techniques.  \\n• Actively participated in Kaggle competitions, applying Data Science skills to solve real-world problems.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-08-22T12:26:38+05:00', 'author': 'Ayesha Saleem', 'moddate': '2025-08-22T12:26:38+05:00', 'source': 'Ayesha_Saleem.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}, page_content='PROJECTS \\nTasteMatch: Transformer-Based Movie Recommender System | Live App \\nTechnologies: Python, NLP, Sentence-BERT, Pandas, Cosine Similarity \\n• Built a content-based recommendation engine using Sentence Transformers (MiniLM-L6-v2) to suggest \\nsimilar movies from a 5K+ movies dataset. \\n• Engineered semantic “tags” by preprocessing metadata including plot, cast, genres, keywords. \\n• Used cosine similarity to compute and rank top-5 similar movies. \\n \\nOncoPredict AI: Early Breast Cancer Detection | GitHub Repository | Kaggle  \\nTechnologies: Python, Scikit-learn, Logistic Regression, Random Forest, EDA \\n• Developed a machine learning pipeline for early breast cancer detection using the Wisconsin \\nDiagnostic Dataset. \\n• Applied Logistic Regression and Random Forest; achieved 98% accuracy and 99% recall with ROC-\\nAUC evaluation, minimizing false negatives. \\n \\nSupplyShield 2.0 – AI-Powered Logistics Risk Detection System | lablab.ai  \\nTechnologies: Streamlit, Claude, LangChain, Plotly, ChromaDB, APIs \\n• Developed a real-time dashboard to detect global shipment risks using weather, news, and logistics \\ndata. \\n• Used Claude LLM to generate risk summaries, suggest actions, and automate stakeholder \\ncommunication. \\n• Integrated LangChain logic, ChromaDB memory, and APIs for alerts, visualizations, and smart \\ndecisions. \\n \\nEDA: Unveiling Sales Patterns | Kaggle  \\n• Performed Exploratory Data Analysis (EDA) on sales data to uncover hidden patterns and trends.  \\n• Applied univariate, bivariate, and multivariate analysis techniques to identify key factors influencing \\nsales performance.  \\n• Visualized insights using Matplotlib and Seaborn, enhancing decision-making.  \\n  \\nLifeLens: Life Expectancy Prediction with Machine Learning | Kaggle  \\n• Developed a machine learning model to predict life expectancy based on health, economic, and social \\nfactors using XGBoost Regressor, performing EDA to identify correlations and data patterns.  \\n• Preprocessing data through encoding, scaling, and missing value imputation.  \\n• Implementing GridSearchCV for hyperparameter tuning to improve model performance.')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b803e2f-ca28-4b2c-8592-72068fde47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [str(doc) for doc in extracted_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c57e845f-c041-45ec-9e09-f15d0b0b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = \"\\n\\n\".join([str(doc) for doc in extracted_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "617e08f5-5870-4978-9175-f9599589be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"page_content='AYESHA SALEEM  \\n+92 318 6706803 | ayeshasaleem853@gmail.com | Portfolio | GitHub | Kaggle  | LinkedIn  \\nACHIEVEMENTS & COMPETITIONS \\n• @Kaggle Expert: Published datasets, notebooks, and competed in real-world ML challenges. \\n• @Harvard CS50x Puzzle Day Winner (2025): Solved all 9/9 puzzles; secured 1st place globally with \\nteam. \\n• @Meta Hacker Cup (2024) Qualifier: Competed in Meta’s global programming competition, showcasing \\nstrong algorithmic and problem-solving skills. \\n• @UC Berkeley CALICO Informatics Competition (2024): Participated to enhance data handling and \\ncomputational thinking. \\n• @LabLab.ai AI Hackathons: Participated in multiple international hackathons focused on generative \\nand applied AI. \\n• @LeetCode 230+ DSA Problems Solved: Practiced advanced algorithmic skills and competitive \\ncoding. \\n \\nTECHNICAL SKILLS \\n• Programming Languages: C++, Python  \\n• Data Science and Machine Learning: NumPy, Pandas, Matplotlib, Seaborn, Scikit-learn, Plotly, \\nTensorFlow, PyTorch, Keras, OpenCV, Hugging face \\n• Frameworks: Streamlit, Gradio  \\n• Version Control: Git, Github  \\n• Developer Tools: VS Code, GoogleCollab, Anaconda, Jupyter Notebook  \\n• Design Tools: Canva \\n \\nEDUCATION  \\nEmerson University Multan                                                                                                Sep. 2023 – Present  \\nBachelor of Science in Computer Science                                                                      Multan, Punjab, Pakistan \\nCGPA: 3.86/4.0  \\nCoursework: Data Structures and Algorithms, Artificial Intelligence, Programming Fundamentals, OOP \\n  \\nEXPERIENCE  \\nC++ Programming Intern                                                                                                 May 2024 – June 2024   \\nCodeAlpha                                                                                                                                                 Remote              \\n• Developed hands-on projects using C++ programming language.  \\n• Gained experience in Object-Oriented Programming (OOP) and Data Structures. \\nContributed to real-world applications by writing clean and efficient code.  \\nKaggle Professional                                                                                                            Sep. 2024 – Present  \\nData Science Community Expert                                                                                                                Global               \\n• Published datasets and notebooks, contributing to the Kaggle community.  \\n• Created and shared data analysis notebooks showcasing Exploratory Data Analysis (EDA) and \\nMachine Learning techniques.  \\n• Actively participated in Kaggle competitions, applying Data Science skills to solve real-world problems.' metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-08-22T12:26:38+05:00', 'author': 'Ayesha Saleem', 'moddate': '2025-08-22T12:26:38+05:00', 'source': 'Ayesha_Saleem.pdf', 'total_pages': 2, 'page': 0, 'page_label': '1'}\\n\\npage_content='PROJECTS \\nTasteMatch: Transformer-Based Movie Recommender System | Live App \\nTechnologies: Python, NLP, Sentence-BERT, Pandas, Cosine Similarity \\n• Built a content-based recommendation engine using Sentence Transformers (MiniLM-L6-v2) to suggest \\nsimilar movies from a 5K+ movies dataset. \\n• Engineered semantic “tags” by preprocessing metadata including plot, cast, genres, keywords. \\n• Used cosine similarity to compute and rank top-5 similar movies. \\n \\nOncoPredict AI: Early Breast Cancer Detection | GitHub Repository | Kaggle  \\nTechnologies: Python, Scikit-learn, Logistic Regression, Random Forest, EDA \\n• Developed a machine learning pipeline for early breast cancer detection using the Wisconsin \\nDiagnostic Dataset. \\n• Applied Logistic Regression and Random Forest; achieved 98% accuracy and 99% recall with ROC-\\nAUC evaluation, minimizing false negatives. \\n \\nSupplyShield 2.0 – AI-Powered Logistics Risk Detection System | lablab.ai  \\nTechnologies: Streamlit, Claude, LangChain, Plotly, ChromaDB, APIs \\n• Developed a real-time dashboard to detect global shipment risks using weather, news, and logistics \\ndata. \\n• Used Claude LLM to generate risk summaries, suggest actions, and automate stakeholder \\ncommunication. \\n• Integrated LangChain logic, ChromaDB memory, and APIs for alerts, visualizations, and smart \\ndecisions. \\n \\nEDA: Unveiling Sales Patterns | Kaggle  \\n• Performed Exploratory Data Analysis (EDA) on sales data to uncover hidden patterns and trends.  \\n• Applied univariate, bivariate, and multivariate analysis techniques to identify key factors influencing \\nsales performance.  \\n• Visualized insights using Matplotlib and Seaborn, enhancing decision-making.  \\n  \\nLifeLens: Life Expectancy Prediction with Machine Learning | Kaggle  \\n• Developed a machine learning model to predict life expectancy based on health, economic, and social \\nfactors using XGBoost Regressor, performing EDA to identify correlations and data patterns.  \\n• Preprocessing data through encoding, scaling, and missing value imputation.  \\n• Implementing GridSearchCV for hyperparameter tuning to improve model performance.' metadata={'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-08-22T12:26:38+05:00', 'author': 'Ayesha Saleem', 'moddate': '2025-08-22T12:26:38+05:00', 'source': 'Ayesha_Saleem.pdf', 'total_pages': 2, 'page': 1, 'page_label': '2'}\""
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9be1316b-da88-4cc7-85d7-be3d2ef4bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_text = prompt.format(text = extracted_text)\n",
    "response = model.invoke(formated_text).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2668e80-0059-4ba2-98a9-78d7e65e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_json(response):\n",
    "    cleaned = re.sub(r\"```(json)?\", \"\", response).strip()\n",
    "    \n",
    "    try:\n",
    "        structured_output = json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Model returned invalid JSON. Raw output:\")\n",
    "        print(response)\n",
    "        structured_output = None\n",
    "    return structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80f7702e-078e-497a-82ad-69d397df83d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'AYESHA SALEEM', 'Email': 'ayeshasaleem853@gmail.com', 'Phone': '+92 318 6706803', 'LinkedIn': 'No idea', 'Skills': ['C++', 'Python', 'NumPy', 'Pandas', 'Matplotlib', 'Seaborn', 'Scikit-learn', 'Plotly', 'TensorFlow', 'PyTorch', 'Keras', 'OpenCV', 'Hugging face', 'Streamlit', 'Gradio', 'Git', 'Github', 'VS Code', 'GoogleCollab', 'Anaconda', 'Jupyter Notebook', 'Canva', 'NLP', 'Sentence-BERT', 'Cosine Similarity', 'Logistic Regression', 'Random Forest', 'EDA', 'XGBoost Regressor', 'LangChain', 'ChromaDB', 'APIs'], 'Education': ['Emerson University Multan\\nBachelor of Science in Computer Science\\nCGPA: 3.86/4.0'], 'Experience': ['C++ Programming Intern\\nCodeAlpha\\nDeveloped hands-on projects using C++ programming language. \\nGained experience in Object-Oriented Programming (OOP) and Data Structures.\\nContributed to real-world applications by writing clean and efficient code.', 'Kaggle Professional\\nData Science Community Expert\\nPublished datasets and notebooks, contributing to the Kaggle community.\\nCreated and shared data analysis notebooks showcasing Exploratory Data Analysis (EDA) and\\nMachine Learning techniques.\\nActively participated in Kaggle competitions, applying Data Science skills to solve real-world problems.'], 'Projects': ['TasteMatch: Transformer-Based Movie Recommender System', 'OncoPredict AI: Early Breast Cancer Detection', 'SupplyShield 2.0 – AI-Powered Logistics Risk Detection System', 'EDA: Unveiling Sales Patterns', 'LifeLens: Life Expectancy Prediction with Machine Learning'], 'Certifications': ['No idea'], 'Languages': ['No idea']}\n"
     ]
    }
   ],
   "source": [
    "print(extract_json(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b727c0c8-1856-40f2-9ae0-b92336856cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C++', 'Python', 'NumPy', 'Pandas', 'Matplotlib', 'Seaborn', 'Scikit-learn', 'Plotly', 'TensorFlow', 'PyTorch', 'Keras', 'OpenCV', 'Hugging face', 'Streamlit', 'Gradio', 'Git', 'Github', 'VS Code', 'GoogleCollab', 'Anaconda', 'Jupyter Notebook', 'Canva', 'NLP', 'Sentence-BERT', 'Cosine Similarity', 'Logistic Regression', 'Random Forest', 'EDA', 'XGBoost Regressor', 'LangChain', 'ChromaDB', 'APIs']\n"
     ]
    }
   ],
   "source": [
    "print(extract_json(response)['Skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6236b-7293-406d-89dd-f2604960cdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
