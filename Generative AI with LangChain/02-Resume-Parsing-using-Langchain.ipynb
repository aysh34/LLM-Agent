{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b681cd-0a1d-44f1-b2ca-231d98921fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-google-genai in d:\\anaconda3\\lib\\site-packages (2.1.9)\n",
      "Requirement already satisfied: langchain-together in d:\\anaconda3\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: pypdf in d:\\anaconda3\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: docx2txt in d:\\anaconda3\\lib\\site-packages (0.9)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.6.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (0.3.74)\n",
      "Requirement already satisfied: pydantic<3,>=2 in d:\\anaconda3\\lib\\site-packages (from langchain-google-genai) (2.10.3)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.40.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in d:\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (6.32.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in d:\\anaconda3\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in d:\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda3\\lib\\site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.4.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (4.12.2)\n",
      "Requirement already satisfied: packaging>=23.2 in d:\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in d:\\anaconda3\\lib\\site-packages (from pydantic<3,>=2->langchain-google-genai) (2.27.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in d:\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.8)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in d:\\anaconda3\\lib\\site-packages (from langchain-together) (3.11.10)\n",
      "Requirement already satisfied: langchain-openai<0.4,>=0.3 in d:\\anaconda3\\lib\\site-packages (from langchain-together) (0.3.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.9.1->langchain-together) (1.18.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.99.9 in d:\\anaconda3\\lib\\site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (1.100.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\anaconda3\\lib\\site-packages (from langchain-openai<0.4,>=0.3->langchain-together) (0.11.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.10.0)\n",
      "Requirement already satisfied: sniffio in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in d:\\anaconda3\\lib\\site-packages (from openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\anaconda3\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai<0.4,>=0.3->langchain-together) (2024.11.6)\n",
      "Requirement already satisfied: orjson>=3.9.14 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in d:\\anaconda3\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain-google-genai) (0.23.0)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.99.9->langchain-openai<0.4,>=0.3->langchain-together) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~otebook (D:\\Anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-google-genai langchain-together pypdf docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a4c826-33a1-4290-9490-85118ed09382",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0aa90cd6-a221-4b22-8144-fcf512fa7e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_together import ChatTogether\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.document_loaders import PyPDFLoader, TextLoader, Docx2txtLoader\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70864b78-6162-48cb-b595-15f75fe1b70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f7a5fc-db28-4df3-b523-d60848cfd93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash',api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af40227f-0643-42c4-95ba-ae7c993532c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.invoke('Summarize the bias-variance tradeoff.').content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc869738-b763-40c0-b404-8b137481fc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert resume parser. Your task is to extract structured information from the resume text below.\n",
    "\n",
    "Return the output as a **single valid JSON object** with the exact following schema:\n",
    "\n",
    "{{\n",
    "  \"Name\": \"string\",\n",
    "  \"Email\": \"string\",\n",
    "  \"Phone\": \"string\",\n",
    "  \"LinkedIn\": \"string\",\n",
    "  \"Skills\": [\"string\"],\n",
    "  \"Education\": [\"string\"],\n",
    "  \"Experience\": [\"string\"],\n",
    "  \"Projects\": [\"string\"],\n",
    "  \"Certifications\": [\"string\"],\n",
    "  \"Languages\": [\"string\"]\n",
    "}}\n",
    "\n",
    "Rules:\n",
    "- If a field cannot be found, set its value to \"No idea\".\n",
    "- Do not add explanations, notes, or extra text — output JSON only.\n",
    "- For lists (Skills, Education, Experience, Projects, Certifications, Languages), return an array of short strings.\n",
    "- Keep the JSON compact and properly formatted.\n",
    "\n",
    "Resume text:\n",
    "{text}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67c58279-4f75-4e77-a993-973ac1e21942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = PromptTemplate(\n",
    "#     template=PROMPT_TEMPLATE,\n",
    "#     input_variables=[\"text\"])\n",
    "# formatted_prompt = prompt.format(text=\"Jane Doe, ML Engineer skilled in TensorFlow, PyTorch...\")\n",
    "\n",
    "\n",
    "# Instantiation using from_template (recommended, automatically detect variables)\n",
    "# build prompt\n",
    "prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc569f44-dcfa-4118-8338-528a56f82ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatted_prompt = prompt.format(text=\"John Doe, Software Engineer with skills in Python, SQL...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23d5d56c-d74c-484f-8e42-8c140aa6d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea52a79f-1e3e-486b-99df-e8753a642a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resume(file_path):\n",
    "    if file_path.lower().endswith(\".pdf\"):\n",
    "        loader = PyPDFLoader(file_path)\n",
    "    elif file_path.lower().endswith(\".docx\"):\n",
    "        loader = Docx2txtLoader(file_path)\n",
    "    elif file_path.lower().endswith(\".txt\"):\n",
    "        loader = TextLoader(file_path)\n",
    "    else:\n",
    "        return None\n",
    "    return loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49f1d3d3-37d2-4509-93ca-7ac05d93d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = load_resume(\"complex_resume.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a9a3d0f-d193-482e-9b1f-75bda71fd15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'complex_resume.docx'}, page_content='Johnathan A. Smith\\nEmail: johnsmith@example.com | Phone: +1 (555) 123-4567 | LinkedIn: linkedin.com/in/johnsmith\\n\\nSkills:\\n- Python, Java, C++, SQL, R, JavaScript, React, Node.js, Django, Flask, TensorFlow, PyTorch, Git, Docker, Kubernetes\\n\\nEducation:\\n- MSc in Artificial Intelligence, Stanford University, 2020\\n- BSc in Computer Science, University of California, Berkeley, 2018\\n\\nExperience:\\n- Senior Machine Learning Engineer | OpenAI (2021-Present)\\n  Leading a team of 5 engineers to build scalable NLP models for enterprise applications.\\n- Data Scientist | Google (2018-2021)\\n  Developed predictive analytics solutions for Google Ads, improving CTR by 15%.\\n\\nProjects:\\n- Smart Resume Parser: Built an NLP-based system to extract structured information from resumes using Python and spaCy.\\n- AI Chatbot: Designed a conversational AI using Transformer models, deployed on AWS.\\n\\nCertifications:\\n- AWS Certified Machine Learning – Specialty\\n- Google Cloud Professional Data Engineer\\n- TensorFlow Developer Certificate\\n\\nLanguages:\\n- English (Native)\\n- French (Intermediate)\\n- Spanish (Basic)')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b803e2f-ca28-4b2c-8592-72068fde47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [str(doc) for doc in extracted_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c57e845f-c041-45ec-9e09-f15d0b0b4f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = \"\\n\\n\".join([str(doc) for doc in extracted_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "617e08f5-5870-4978-9175-f9599589be6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"page_content='Johnathan A. Smith\\nEmail: johnsmith@example.com | Phone: +1 (555) 123-4567 | LinkedIn: linkedin.com/in/johnsmith\\n\\nSkills:\\n- Python, Java, C++, SQL, R, JavaScript, React, Node.js, Django, Flask, TensorFlow, PyTorch, Git, Docker, Kubernetes\\n\\nEducation:\\n- MSc in Artificial Intelligence, Stanford University, 2020\\n- BSc in Computer Science, University of California, Berkeley, 2018\\n\\nExperience:\\n- Senior Machine Learning Engineer | OpenAI (2021-Present)\\n  Leading a team of 5 engineers to build scalable NLP models for enterprise applications.\\n- Data Scientist | Google (2018-2021)\\n  Developed predictive analytics solutions for Google Ads, improving CTR by 15%.\\n\\nProjects:\\n- Smart Resume Parser: Built an NLP-based system to extract structured information from resumes using Python and spaCy.\\n- AI Chatbot: Designed a conversational AI using Transformer models, deployed on AWS.\\n\\nCertifications:\\n- AWS Certified Machine Learning – Specialty\\n- Google Cloud Professional Data Engineer\\n- TensorFlow Developer Certificate\\n\\nLanguages:\\n- English (Native)\\n- French (Intermediate)\\n- Spanish (Basic)' metadata={'source': 'complex_resume.docx'}\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9be1316b-da88-4cc7-85d7-be3d2ef4bbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "formated_text = prompt.format(text = extracted_text)\n",
    "response = model.invoke(formated_text).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2668e80-0059-4ba2-98a9-78d7e65e499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_json(response):\n",
    "    cleaned = re.sub(r\"```(json)?\", \"\", response).strip()\n",
    "    \n",
    "    try:\n",
    "        structured_output = json.loads(cleaned)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Model returned invalid JSON. Raw output:\")\n",
    "        print(response)\n",
    "        structured_output = None\n",
    "    return structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80f7702e-078e-497a-82ad-69d397df83d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': 'Johnathan A. Smith', 'Email': 'johnsmith@example.com', 'Phone': '+1 (555) 123-4567', 'LinkedIn': 'linkedin.com/in/johnsmith', 'Skills': ['Python', 'Java', 'C++', 'SQL', 'R', 'JavaScript', 'React', 'Node.js', 'Django', 'Flask', 'TensorFlow', 'PyTorch', 'Git', 'Docker', 'Kubernetes'], 'Education': ['MSc in Artificial Intelligence, Stanford University, 2020', 'BSc in Computer Science, University of California, Berkeley, 2018'], 'Experience': ['Senior Machine Learning Engineer | OpenAI (2021-Present)', 'Data Scientist | Google (2018-2021)'], 'Projects': ['Smart Resume Parser: Built an NLP-based system to extract structured information from resumes using Python and spaCy.', 'AI Chatbot: Designed a conversational AI using Transformer models, deployed on AWS.'], 'Certifications': ['AWS Certified Machine Learning – Specialty', 'Google Cloud Professional Data Engineer', 'TensorFlow Developer Certificate'], 'Languages': ['English (Native)', 'French (Intermediate)', 'Spanish (Basic)']}\n"
     ]
    }
   ],
   "source": [
    "print(extract_json(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b727c0c8-1856-40f2-9ae0-b92336856cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python', 'Java', 'C++', 'SQL', 'R', 'JavaScript', 'React', 'Node.js', 'Django', 'Flask', 'TensorFlow', 'PyTorch', 'Git', 'Docker', 'Kubernetes']\n"
     ]
    }
   ],
   "source": [
    "print(extract_json(response)['Skills'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6236b-7293-406d-89dd-f2604960cdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
